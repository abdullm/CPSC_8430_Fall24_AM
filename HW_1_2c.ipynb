{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f71e60-04d9-4dc7-ab33-8bb888b0885a",
   "metadata": {},
   "source": [
    "## CPSC 8430 Fall 24 HW 1_2c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cc1daf-2628-4b93-b2c5-bf23738f3c1f",
   "metadata": {},
   "source": [
    "#### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf1482d-4d78-4b58-bc67-52b2242b8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5da0f9e-a893-4cb3-9942-78fe76a3bb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f319c1744d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable anomaly detection for debugging\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb46b8-2e4f-4054-8697-17d9adb71ad8",
   "metadata": {},
   "source": [
    "#### 2. Define DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b5fa4e-a877-47c5-ba0d-ef67d30f1b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 16)  # Input size is 1 (for x)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782e8a11-5e41-43a7-9843-0dfe80fcfc56",
   "metadata": {},
   "source": [
    "#### Function to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15f0d02-cbdc-40d2-a5da-8e7465ca5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_samples):\n",
    "    x = torch.rand(num_samples, 1)  # Random x values between 0 and 1\n",
    "    y = torch.sin(5 * torch.pi * x) / (5 * torch.pi * x)  # Calculate corresponding y values\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebd8a1-1038-4148-9586-b14feae7c237",
   "metadata": {},
   "source": [
    "#### 3. Function for calculating gradient norm (p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbde5160-3baa-427f-849e-f454927d8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient_norm(model):\n",
    "    grad_all = 0.0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            grad = (p.grad.cpu().data.numpy() ** 2).sum()\n",
    "            grad_all += grad\n",
    "    grad_norm = grad_all ** 0.5\n",
    "    return grad_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d43ba0-21a0-4f16-aa95-e3e77968b262",
   "metadata": {},
   "source": [
    "#### 4. Function for calculating Hessian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2886367a-d18e-4f54-93d0-fcf93c6073ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessian_diagonal(model, loss):\n",
    "    hessian = []\n",
    "    for param in model.parameters():\n",
    "        grad_params = grad(loss, param, create_graph=True)[0]\n",
    "        grad_params_flat = grad_params.contiguous().view(-1)\n",
    "        row = []\n",
    "        for g in grad_params_flat:\n",
    "            grad2nd = grad(g, param, retain_graph=True)[0]\n",
    "            row.append(grad2nd.contiguous().view(-1))\n",
    "        hessian.append(torch.cat(row))\n",
    "    return torch.cat(hessian).diag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2c00e-e8fa-4738-b654-17b6ae963ec8",
   "metadata": {},
   "source": [
    "#### 5. Function for calculating minimul ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f32d876-9897-4a17-8a92-fd10183bba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_minimal_ratio(hessian):\n",
    "    eigenvalues = torch.linalg.eigvalsh(hessian.cpu())\n",
    "    positive_eigenvalues = torch.sum(eigenvalues > 0)\n",
    "    total_eigenvalues = len(eigenvalues)\n",
    "    minimal_ratio = positive_eigenvalues.item() / total_eigenvalues\n",
    "    return minimal_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e3c7ae-17b2-4e53-93f7-cf0697add853",
   "metadata": {},
   "source": [
    "#### 6. Function to compute losses and sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63ec3ec-8927-4bf0-a105-458e52de8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_compute_loss(model, theta_0, sample_count, loss_function, inputs, labels):\n",
    "    sampled_losses = []\n",
    "    for _ in range(sample_count):\n",
    "        # Generate random weights around theta_0\n",
    "        sampled_params = [p + torch.randn_like(p) * 0.01 for p in theta_0]\n",
    "        for param, sample in zip(model.parameters(), sampled_params):\n",
    "            param.data.copy_(sample)\n",
    "\n",
    "        # Compute the loss for this sampled weight set\n",
    "        outputs = model(inputs)\n",
    "        loss_sample = loss_function(outputs, labels)\n",
    "        sampled_losses.append(loss_sample.item())\n",
    "\n",
    "    return sampled_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2155bb-d8bb-4689-aa33-289a53be7d03",
   "metadata": {},
   "source": [
    "#### 6. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b25e7d33-5457-4107-8df7-dda0431b0907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.0031, Gradient Norm: 0.2131\n",
      "Epoch 2/100, Loss: 0.0141, Gradient Norm: 0.5139\n",
      "Epoch 3/100, Loss: 0.0218, Gradient Norm: 0.6942\n",
      "Epoch 4/100, Loss: 0.0196, Gradient Norm: 0.6629\n",
      "Epoch 5/100, Loss: 0.0163, Gradient Norm: 0.6035\n",
      "Epoch 6/100, Loss: 0.0123, Gradient Norm: 0.5283\n",
      "Epoch 7/100, Loss: 0.0092, Gradient Norm: 0.4663\n",
      "Epoch 8/100, Loss: 0.0068, Gradient Norm: 0.4113\n",
      "Epoch 9/100, Loss: 0.0049, Gradient Norm: 0.3617\n",
      "Epoch 10, Iteration 154, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 10, Iteration 154, Loss: 0.000000, Minimal Ratio: 0.146667, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 10/100, Loss: 0.0042, Gradient Norm: 0.3436\n",
      "Epoch 11/100, Loss: 0.0034, Gradient Norm: 0.3224\n",
      "Epoch 12/100, Loss: 0.0028, Gradient Norm: 0.3101\n",
      "Epoch 13/100, Loss: 0.0023, Gradient Norm: 0.2903\n",
      "Epoch 14, Iteration 786, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 14, Iteration 786, Loss: 0.000000, Minimal Ratio: 0.055389, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 14/100, Loss: 0.0015, Gradient Norm: 0.2459\n",
      "Epoch 15/100, Loss: 0.0013, Gradient Norm: 0.2309\n",
      "Epoch 16, Iteration 305, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 16, Iteration 305, Loss: 0.000000, Minimal Ratio: 0.156887, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 16/100, Loss: 0.0010, Gradient Norm: 0.2177\n",
      "Epoch 17/100, Loss: 0.0008, Gradient Norm: 0.1957\n",
      "Epoch 18, Iteration 232, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 18, Iteration 232, Loss: 0.000000, Minimal Ratio: 0.131924, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 18/100, Loss: 0.0007, Gradient Norm: 0.1833\n",
      "Epoch 19/100, Loss: 0.0006, Gradient Norm: 0.1739\n",
      "Epoch 20/100, Loss: 0.0005, Gradient Norm: 0.1562\n",
      "Epoch 21, Iteration 331, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 21, Iteration 331, Loss: 0.000000, Minimal Ratio: 0.156887, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 21/100, Loss: 0.0003, Gradient Norm: 0.1222\n",
      "Epoch 22/100, Loss: 0.0003, Gradient Norm: 0.1184\n",
      "Epoch 23/100, Loss: 0.0002, Gradient Norm: 0.1080\n",
      "Epoch 24/100, Loss: 0.0002, Gradient Norm: 0.1038\n",
      "Epoch 25, Iteration 26, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 25, Iteration 26, Loss: 0.000000, Minimal Ratio: 0.081233, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 25/100, Loss: 0.0002, Gradient Norm: 0.1095\n",
      "Epoch 26, Iteration 8, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 26, Iteration 8, Loss: 0.000000, Minimal Ratio: 0.067137, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 26/100, Loss: 0.0003, Gradient Norm: 0.1202\n",
      "Epoch 27/100, Loss: 0.0003, Gradient Norm: 0.1228\n",
      "Epoch 28/100, Loss: 0.0003, Gradient Norm: 0.1232\n",
      "Epoch 29/100, Loss: 0.0003, Gradient Norm: 0.1229\n",
      "Epoch 30/100, Loss: 0.0002, Gradient Norm: 0.1057\n",
      "Epoch 31, Iteration 114, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 31, Iteration 114, Loss: 0.000000, Minimal Ratio: 0.054449, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 31/100, Loss: 0.0002, Gradient Norm: 0.0960\n",
      "Epoch 32/100, Loss: 0.0002, Gradient Norm: 0.0966\n",
      "Epoch 33, Iteration 899, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 33, Iteration 899, Loss: 0.000000, Minimal Ratio: 0.130514, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 33, Iteration 966, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 33, Iteration 966, Loss: 0.000000, Minimal Ratio: 0.155007, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 33/100, Loss: 0.0000, Gradient Norm: 0.0298\n",
      "Epoch 34/100, Loss: 0.0001, Gradient Norm: 0.0833\n",
      "Epoch 35/100, Loss: 0.0001, Gradient Norm: 0.0783\n",
      "Epoch 36/100, Loss: 0.0001, Gradient Norm: 0.0769\n",
      "Epoch 37, Iteration 582, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 37, Iteration 582, Loss: 0.000000, Minimal Ratio: 0.146667, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 37/100, Loss: 0.0001, Gradient Norm: 0.0640\n",
      "Epoch 38/100, Loss: 0.0001, Gradient Norm: 0.0669\n",
      "Epoch 39/100, Loss: 0.0001, Gradient Norm: 0.0647\n",
      "Epoch 40/100, Loss: 0.0001, Gradient Norm: 0.0626\n",
      "Epoch 41/100, Loss: 0.0001, Gradient Norm: 0.0565\n",
      "Epoch 42/100, Loss: 0.0001, Gradient Norm: 0.0559\n",
      "Epoch 43, Iteration 502, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 43, Iteration 502, Loss: 0.000000, Minimal Ratio: 0.067137, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 43/100, Loss: 0.0001, Gradient Norm: 0.0553\n",
      "Epoch 44/100, Loss: 0.0001, Gradient Norm: 0.0582\n",
      "Epoch 45/100, Loss: 0.0001, Gradient Norm: 0.0552\n",
      "Epoch 46/100, Loss: 0.0001, Gradient Norm: 0.0540\n",
      "Epoch 47, Iteration 43, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 47, Iteration 43, Loss: 0.000000, Minimal Ratio: 0.155712, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 47/100, Loss: 0.0001, Gradient Norm: 0.0584\n",
      "Epoch 48/100, Loss: 0.0000, Gradient Norm: 0.0498\n",
      "Epoch 49/100, Loss: 0.0000, Gradient Norm: 0.0458\n",
      "Epoch 50/100, Loss: 0.0000, Gradient Norm: 0.0453\n",
      "Epoch 51/100, Loss: 0.0000, Gradient Norm: 0.0455\n",
      "Epoch 52/100, Loss: 0.0000, Gradient Norm: 0.0442\n",
      "Epoch 53/100, Loss: 0.0000, Gradient Norm: 0.0434\n",
      "Epoch 54/100, Loss: 0.0000, Gradient Norm: 0.0434\n",
      "Epoch 55/100, Loss: 0.0000, Gradient Norm: 0.0395\n",
      "Epoch 56, Iteration 439, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 56, Iteration 439, Loss: 0.000000, Minimal Ratio: 0.023671, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 56/100, Loss: 0.0001, Gradient Norm: 0.0612\n",
      "Epoch 57/100, Loss: 0.0000, Gradient Norm: 0.0454\n",
      "Epoch 58/100, Loss: 0.0000, Gradient Norm: 0.0358\n",
      "Epoch 59, Iteration 690, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 59, Iteration 690, Loss: 0.000000, Minimal Ratio: 0.079824, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 59, Iteration 851, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 59, Iteration 851, Loss: 0.000000, Minimal Ratio: 0.036358, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 59/100, Loss: 0.0001, Gradient Norm: 0.0524\n",
      "Epoch 60/100, Loss: 0.0000, Gradient Norm: 0.0381\n",
      "Epoch 61/100, Loss: 0.0000, Gradient Norm: 0.0389\n",
      "Epoch 62, Iteration 973, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 62, Iteration 973, Loss: 0.000000, Minimal Ratio: 0.023671, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 62/100, Loss: 0.0000, Gradient Norm: 0.0329\n",
      "Epoch 63/100, Loss: 0.0000, Gradient Norm: 0.0285\n",
      "Epoch 64/100, Loss: 0.0000, Gradient Norm: 0.0343\n",
      "Epoch 65, Iteration 577, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 65, Iteration 577, Loss: 0.000000, Minimal Ratio: 0.072247, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 65/100, Loss: 0.0000, Gradient Norm: 0.0273\n",
      "Epoch 66, Iteration 44, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 66, Iteration 44, Loss: 0.000000, Minimal Ratio: 0.018267, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 66/100, Loss: 0.0000, Gradient Norm: 0.0138\n",
      "Epoch 67/100, Loss: 0.0000, Gradient Norm: 0.0107\n",
      "Epoch 68/100, Loss: 0.0000, Gradient Norm: 0.0089\n",
      "Epoch 69/100, Loss: 0.0000, Gradient Norm: 0.0087\n",
      "Epoch 70/100, Loss: 0.0000, Gradient Norm: 0.0094\n",
      "Epoch 71/100, Loss: 0.0000, Gradient Norm: 0.0106\n",
      "Epoch 72/100, Loss: 0.0000, Gradient Norm: 0.0114\n",
      "Epoch 73, Iteration 330, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 73, Iteration 330, Loss: 0.000000, Minimal Ratio: 0.025786, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 73, Iteration 833, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 73, Iteration 833, Loss: 0.000000, Minimal Ratio: 0.081233, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 73/100, Loss: 0.0003, Gradient Norm: 0.0529\n",
      "Epoch 74/100, Loss: 0.0000, Gradient Norm: 0.0175\n",
      "Epoch 75, Iteration 495, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 75, Iteration 495, Loss: 0.000000, Minimal Ratio: 0.025786, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 75/100, Loss: 0.0000, Gradient Norm: 0.0161\n",
      "Epoch 76/100, Loss: 0.0000, Gradient Norm: 0.0109\n",
      "Epoch 77/100, Loss: 0.0000, Gradient Norm: 0.0079\n",
      "Epoch 78/100, Loss: 0.0000, Gradient Norm: 0.0080\n",
      "Epoch 79/100, Loss: 0.0000, Gradient Norm: 0.0112\n",
      "Epoch 80/100, Loss: 0.0000, Gradient Norm: 0.0121\n",
      "Epoch 81/100, Loss: 0.0000, Gradient Norm: 0.0124\n",
      "Epoch 82/100, Loss: 0.0000, Gradient Norm: 0.0124\n",
      "Epoch 83, Iteration 619, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 83, Iteration 619, Loss: 0.000000, Minimal Ratio: 0.044053, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 83/100, Loss: 0.0000, Gradient Norm: 0.0158\n",
      "Epoch 84/100, Loss: 0.0000, Gradient Norm: 0.0139\n",
      "Epoch 85/100, Loss: 0.0000, Gradient Norm: 0.0135\n",
      "Epoch 86/100, Loss: 0.0000, Gradient Norm: 0.0127\n",
      "Epoch 87/100, Loss: 0.0000, Gradient Norm: 0.0125\n",
      "Epoch 88, Iteration 702, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 88, Iteration 702, Loss: 0.000000, Minimal Ratio: 0.036358, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 88/100, Loss: 0.0001, Gradient Norm: 0.0264\n",
      "Epoch 89/100, Loss: 0.0000, Gradient Norm: 0.0174\n",
      "Epoch 90, Iteration 867, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 90, Iteration 867, Loss: 0.000000, Minimal Ratio: 0.036123, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 90/100, Loss: 0.0000, Gradient Norm: 0.0165\n",
      "Epoch 91/100, Loss: 0.0000, Gradient Norm: 0.0130\n",
      "Epoch 92/100, Loss: 0.0000, Gradient Norm: 0.0129\n",
      "Epoch 93, Iteration 902, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 93, Iteration 902, Loss: 0.000000, Minimal Ratio: 0.011160, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 93/100, Loss: 0.0001, Gradient Norm: 0.0243\n",
      "Epoch 94/100, Loss: 0.0000, Gradient Norm: 0.0137\n",
      "Epoch 95/100, Loss: 0.0000, Gradient Norm: 0.0135\n",
      "Epoch 96, Iteration 1, Switching to Gradient Norm Minimization\n",
      "Hessian computation done\n",
      "Minimal Ratio computation done\n",
      "Epoch 96, Iteration 1, Loss: 0.000000, Minimal Ratio: 0.043583, Proportion L(sample) > L(theta_0): 1.000000\n",
      "Epoch 96/100, Loss: 0.0000, Gradient Norm: 0.0123\n",
      "Epoch 97/100, Loss: 0.0000, Gradient Norm: 0.0131\n",
      "Epoch 98/100, Loss: 0.0000, Gradient Norm: 0.0135\n",
      "Epoch 99/100, Loss: 0.0000, Gradient Norm: 0.0139\n",
      "Epoch 100/100, Loss: 0.0000, Gradient Norm: 0.0147\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 100\n",
    "grad_norm_threshold = 5e-5  # Threshold to switch to gradient norm minimization\n",
    "minimal_ratios = []\n",
    "losses = []\n",
    "early_stopping_patience = 10 \n",
    "\n",
    "# Generate data\n",
    "num_samples = 1000\n",
    "x, y = generate_data(num_samples)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = DNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(num_samples):\n",
    "        model.zero_grad()\n",
    "        outputs = model(x[i].unsqueeze(0))  \n",
    "        loss = nn.MSELoss()(outputs, y[i].unsqueeze(0))\n",
    "        loss.backward(retain_graph=True)  # retain the graph for second-order derivatives\n",
    "\n",
    "        grad_norm = calculate_gradient_norm(model)\n",
    "\n",
    "        # Switch to minimizing gradient norm if it is below the threshold\n",
    "        if grad_norm < grad_norm_threshold:\n",
    "            print(f\"Epoch {epoch + 1}, Iteration {i + 1}, Switching to Gradient Norm Minimization\")\n",
    "\n",
    "            # Compute Hessian (using diagonal approximation)\n",
    "            hessian = compute_hessian_diagonal(model, loss)\n",
    "            print(\"Hessian computation done\")\n",
    "\n",
    "            # Compute minimal ratio using the Hessian's eigenvalues\n",
    "            minimal_ratio = compute_minimal_ratio(hessian)\n",
    "            minimal_ratios.append(minimal_ratio)\n",
    "            print(\"Minimal Ratio computation done\")\n",
    "\n",
    "            # Sample multiple weights around this point and compute losses\n",
    "            theta_0 = [p.data.clone() for p in model.parameters()]  # Save the current weights (theta_0)\n",
    "            sampled_losses = sample_and_compute_loss(model, theta_0, sample_count=10,\n",
    "                                                    loss_function=nn.MSELoss(),\n",
    "                                                    inputs=x[i].unsqueeze(0), labels=y[i].unsqueeze(0))\n",
    "\n",
    "            # Calculate how many of the sampled losses are greater than the original loss\n",
    "            proportion_greater = sum([1 for sl in sampled_losses if sl > loss.item()]) / len(sampled_losses)\n",
    "\n",
    "            # Print the detailed output\n",
    "            print(f\"Epoch {epoch + 1}, Iteration {i + 1}, Loss: {loss.item():.6f}, Minimal Ratio: {minimal_ratio:.6f}, Proportion L(sample) > L(theta_0): {proportion_greater:.6f}\")\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        # Update weights at the end using optimizer based on the original loss\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print outputs for the epoch\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Gradient Norm: {grad_norm:.4f}')\n",
    "\n",
    "    # Early stopping check\n",
    "    if len(minimal_ratios) > early_stopping_patience and all(mr < minimal_ratios[-early_stopping_patience] for mr in minimal_ratios[-early_stopping_patience:]):\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a73c3-3f5a-42df-a010-4be2e8699721",
   "metadata": {},
   "source": [
    "#### 7. Plotting minimal ratio vs loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce1012e-c461-4d36-b81b-c18f51d82256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(minimal_ratios, losses)\n",
    "plt.xlabel('Minimal Ratio')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Minimal Ratio vs Loss when Gradient is Almost Zero')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
